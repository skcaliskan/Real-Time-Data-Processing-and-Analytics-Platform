{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,com.datastax.spark:spark-cassandra-connector_2.12:3.2.0  --driver-memory 1g --executor-memory 1g\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"spark-kafka-cassandra_read\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"Ip_Adress\") \\\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "df = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"Ip_Adress:9092\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\")\\\n",
    "    .option(\"subscribe\", \"powerbreakdown\").load()\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, TimestampType, DoubleType, MapType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"zone\", StringType()),\n",
    "    StructField(\"datetime\", StringType()),\n",
    "    StructField(\"updatedAt\", StringType()),\n",
    "    StructField(\"createdAt\", StringType()),\n",
    "    StructField(\"powerConsumptionBreakdown\", MapType(StringType(), IntegerType())),\n",
    "    StructField(\"powerProductionBreakdown\", MapType(StringType(), IntegerType())),\n",
    "    StructField(\"powerImportBreakdown\", MapType(StringType(), IntegerType())),\n",
    "    StructField(\"powerExportBreakdown\", MapType(StringType(), IntegerType())),\n",
    "    StructField(\"fossilFreePercentage\", IntegerType()),\n",
    "    StructField(\"renewablePercentage\", IntegerType()),\n",
    "    StructField(\"powerConsumptionTotal\", IntegerType()),\n",
    "    StructField(\"powerProductionTotal\", IntegerType()),\n",
    "    StructField(\"powerImportTotal\", IntegerType()),\n",
    "    StructField(\"powerExportTotal\", IntegerType()),\n",
    "    StructField(\"isEstimated\", BooleanType()),\n",
    "    StructField(\"estimationMethod\", StringType()),\n",
    "    StructField(\"GetDataDateTime\", StringType()),\n",
    "    StructField(\"id\", StringType()),\n",
    "    StructField(\"zoneid\", IntegerType())\n",
    "])\n",
    "\n",
    "df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "from pyspark.sql.functions import from_json, col\n",
    "df = df.withColumn(\"value\", from_json(\"value\", schema)).select(\"value.*\")\n",
    "\n",
    "\n",
    "json_df = df.select(\n",
    "    \"id\",\n",
    "    \"zoneid\",\n",
    "    \"zone\",\n",
    "    \"getdatadatetime\",\n",
    "    col(\"powerConsumptionBreakdown.nuclear\").alias(\"cons_nuclear\"),\n",
    "    col(\"powerConsumptionBreakdown.geothermal\").alias(\"cons_geothermal\"),\n",
    "    col(\"powerConsumptionBreakdown.biomass\").alias(\"cons_biomass\"),\n",
    "    col(\"powerConsumptionBreakdown.coal\").alias(\"cons_coal\"),\n",
    "    col(\"powerConsumptionBreakdown.solar\").alias(\"cons_solar\"),\n",
    "    col(\"powerConsumptionBreakdown.wind\").alias(\"cons_wind\"),\n",
    "    col(\"powerConsumptionBreakdown.hydro\").alias(\"cons_hydro\"),\n",
    "    col(\"powerConsumptionBreakdown.gas\").alias(\"cons_gas\"),\n",
    "    col(\"powerConsumptionBreakdown.oil\").alias(\"cons_oil\"),\n",
    "    col(\"powerConsumptionBreakdown.unknown\").alias(\"cons_unknown\"),\n",
    "    col(\"powerProductionBreakdown.nuclear\").alias(\"prod_nuclear\"),\n",
    "    col(\"powerProductionBreakdown.geothermal\").alias(\"prod_geothermal\"),\n",
    "    col(\"powerProductionBreakdown.biomass\").alias(\"prod_biomass\"),\n",
    "    col(\"powerProductionBreakdown.coal\").alias(\"prod_coal\"),\n",
    "    col(\"powerProductionBreakdown.solar\").alias(\"prod_solar\"),\n",
    "    col(\"powerProductionBreakdown.wind\").alias(\"prod_wind\"),\n",
    "    col(\"powerProductionBreakdown.hydro\").alias(\"prod_hydro\"),\n",
    "    col(\"powerProductionBreakdown.gas\").alias(\"prod_gas\"),\n",
    "    col(\"powerProductionBreakdown.oil\").alias(\"prod_oil\"),\n",
    "    col(\"powerProductionBreakdown.unknown\").alias(\"prod_unknown\"),\n",
    "    col(\"powerConsumptionTotal\").alias(\"consumption_total\"),\n",
    "    col(\"powerProductionTotal\").alias(\"production_total\"),\n",
    "    col(\"powerImportTotal\").alias(\"import_total\"),\n",
    "    col(\"powerExportTotal\").alias(\"export_total\")\n",
    ")\n",
    "\n",
    "json_df=json_df.fillna(0)\n",
    "\n",
    "json_df.writeStream.format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .option(\"keyspace\", \"power\") \\\n",
    "    .option(\"table\", \"powerbreakdown\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoint\") \\\n",
    "    .start() \\\n",
    "    .awaitTermination()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
